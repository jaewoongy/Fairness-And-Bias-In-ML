{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c621447",
   "metadata": {},
   "source": [
    "## Homework 2: Intro to bias and fairness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3b9642c",
   "metadata": {},
   "source": [
    "Download the German Credit dataset: https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
    "(use the “numeric” version of the data)\n",
    "\n",
    "Implement a (logistic regression) classification pipeline using an 80/20 test split. Use a regularization value of C = 1.\n",
    "\n",
    "Treat the 20th feature (i.e., feat[19] in the numeric data, which is\n",
    "related to housing) as the “sensitive attribute” i.e., z=1 if the feature value is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f42dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "german_credit = np.loadtxt('german.data-numeric')\n",
    "attrs = german_credit[:, :-1] \n",
    "labels = 2 - german_credit[:, -1] # (1 = Good,  2 = Bad) -> (0=Bad, 1=good)\n",
    "\n",
    "split_point = 800\n",
    "X_train, X_test = attrs[:split_point], attrs[split_point:]\n",
    "y_train, y_test = labels[:split_point], labels[split_point:]\n",
    "\n",
    "sensitive_attribute = 19\n",
    "\n",
    "model = LogisticRegression(C=1, max_iter=1000, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce91dbf0",
   "metadata": {},
   "source": [
    "1. Report the prevalence in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9305af18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = np.mean(y_test)\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4845af",
   "metadata": {},
   "source": [
    "2. Report the per-group prevalence for z=0 and z=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2be0627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7204968944099379, 0.5897435897435898)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence_0 = np.mean(y_test[X_test[:, 19] == 0])\n",
    "prevalence_1 = np.mean(y_test[X_test[:, 19] == 1])\n",
    "prevalence_0, prevalence_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca0bdadb",
   "metadata": {},
   "source": [
    "3. What is the demographic parity (expressed as a ratio between z=0 and z=1) for your classifier on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f909f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2014906832298136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "y_pred_0 = y_pred[X_test[:, sensitive_attribute] == 0]\n",
    "y_pred_1 = y_pred[X_test[:, sensitive_attribute] == 1]\n",
    "y_test_0 = y_test[X_test[:, sensitive_attribute] == 0]\n",
    "y_test_1 = y_test[X_test[:, sensitive_attribute] == 1]\n",
    "parity = np.mean(y_pred_0) / np.mean(y_pred_1)\n",
    "parity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d94e8371",
   "metadata": {},
   "source": [
    "4. Report TPR_0, TPR_1, FPR_0, and FPR_1 (see \"equal opportunity\" slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a74d893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8879310344827587, 0.8695652173913043, 0.4666666666666667, 0.3125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    # might be useful to fill this helper function\n",
    "    # feel free to ignore this though\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    tp = conf_mat[1][1]\n",
    "    fn = conf_mat[1][0]\n",
    "    tn = conf_mat[0][0]\n",
    "    fp = conf_mat[0][1]\n",
    "    return tp, fn, tn, fp\n",
    "\n",
    "tp0, fn0, tn0, fp0 = get_metrics(y_test_0, y_pred_0)\n",
    "tp1, fn1, tn1, fp1 = get_metrics(y_test_1, y_pred_1)\n",
    "\n",
    "TPR_0 = tp0 / (tp0 + fn0)\n",
    "TPR_1 = tp1 / (tp1 + fn1)\n",
    "\n",
    "FPR_0 = fp0 / (fp0 + tn0)\n",
    "FPR_1 = fp1 / (fp1 + tn1)\n",
    "\n",
    "TPR_0, TPR_1, FPR_0, FPR_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cfa79c3",
   "metadata": {},
   "source": [
    "5. Compute PPV_0, PPV_1, NPV_0, and NPV_1 (see \"are fairness goals compatible\" slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662715ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8306451612903226, 0.8, 0.6486486486486487, 0.7857142857142857)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPV_0 = tp0 / (tp0 + fp0)\n",
    "PPV_1 = tp1 / (tp1 + fp1)\n",
    "\n",
    "NPV_0 = tn0 / (tn0 + fn0)\n",
    "NPV_1 = tn1 / (tn1 + fn1)\n",
    "\n",
    "PPV_0, PPV_1, NPV_0, NPV_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a3d072",
   "metadata": {},
   "source": [
    "6. Implement a \"fairness through unawareness\" classifier, i.e., don't use Z in your feature vector. Find the classifier coefficient which undergoes the largest (absolute value) change compared to the classifier with the feature included, and report its new coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b63934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_z = np.delete(X_train, sensitive_attribute, axis=1)\n",
    "X_test_no_z = np.delete(X_test, sensitive_attribute, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b504483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_model = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "new_model.fit(X_train_no_z, y_train)\n",
    "y_pred_no_z = new_model.predict(X_test_no_z)\n",
    "\n",
    "curr_coeff = new_model.coef_[0]\n",
    "old_coeff = np.delete(model.coef_[0], 19)\n",
    "\n",
    "#np.abs(curr_coeff - old_coeff).argmax()\n",
    "biggest_change_idx = np.abs(curr_coeff - old_coeff).argmax()\n",
    "\n",
    "new_coeff = new_model.coef_[0][biggest_change_idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a843563",
   "metadata": {},
   "source": [
    "7. Report the demographic parity of the classifier after implementing the above intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae577cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763539282990084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_pred_0 = y_pred_no_z[X_test_no_z[:, sensitive_attribute] == 0]\n",
    "new_y_pred_1 = y_pred_no_z[X_test_no_z[:, sensitive_attribute] == 1]\n",
    "\n",
    "new_parity = np.mean(new_y_pred_0) / np.mean(new_y_pred_1)\n",
    "new_parity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcdb181b",
   "metadata": {},
   "source": [
    "8. Report the Generalized False Positive Rate and Generalized False Negative Rate of your original (i.e., not the one with z excluded).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2eb94e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 51)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "len(y_prob), len(y_prob[y_pred == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03aa5e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26900494316934026, 0.1991360308306282)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp, fn, tn, fp = get_metrics(y_test, y_pred)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "GFPR = 1 / (fp + tn) * np.sum(y_prob[y_pred == 0])\n",
    "GFNR = 1 / (fn + tp) * np.sum(1 - y_prob[y_pred == 1])\n",
    "\n",
    "GFPR, GFNR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "968ab77b",
   "metadata": {},
   "source": [
    "9. (harder, 2 marks) Changing the classifier threshold (much as you would to generate an ROC curve) will change the False Positive and False Negative rates for both groups (i.e., FP_0, FP_1, FN_0, FN_1). Implement a \"fairness through unawareness\" classifier like you did in Question 6 but instead use feature 19 (i.e., feat[18]) as the sensitive attribute. Using this classifier, find the (non-trivial) threshold that comes closest to achieving Treatment Equality, and report the corresponding values of FP_0, FP_1, FN_0, and FN_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356c2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "sensitive_attribute = 18\n",
    "new_model = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "X_train_no_18 = np.delete(X_train, sensitive_attribute, axis=1)\n",
    "X_test_no_18 = np.delete(X_test, sensitive_attribute, axis=1)\n",
    "new_model.fit(X_train_no_18, y_train)\n",
    "pred_prob = new_model.predict_proba(X_test_no_18)[:, 1]\n",
    "y_pred_threshold = (pred_prob > threshold).astype(int)\n",
    "\n",
    "y_pred_0 = y_pred_threshold[X_test[:, sensitive_attribute] == 0]\n",
    "y_pred_1 = y_pred_threshold[X_test[:, sensitive_attribute] == 1]\n",
    "y_test_0 = y_test[X_test[:, sensitive_attribute] == 0]\n",
    "y_test_1 = y_test[X_test[:, sensitive_attribute] == 1]\n",
    "\n",
    "tp0, fn0, tn0, fp0 = get_metrics(y_test_0, y_pred_0)\n",
    "tp1, fn1, tn1, fp1 = get_metrics(y_test_1, y_pred_1)\n",
    "\n",
    "# If this is 1.0 then the treatment is equal\n",
    "fp1 * fn0 / fp0 * fn1\n",
    "\n",
    "FP_0, FP_1, FN_0, FN_1 = fp0, fp1, fn0, fn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82a6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {\n",
    "    \"Q1\": prevalence,           # prevalence\n",
    "    \"Q2\": [prevalence_0, prevalence_1],  # prevalence_0, prevalence_1\n",
    "    \"Q3\": parity,           # parity\n",
    "    \"Q4\": [TPR_0, TPR_1, FPR_0, FPR_0], # TPR_0, TPR_1, FPR_0, FPR_1\n",
    "    \"Q5\": [PPV_0, PPV_1, NPV_0, NPV_1], # PPV_0, PPV_1, NPV_0, NPV_1\n",
    "    \"Q6\": [biggest_change_idx, new_coeff], # feature index, coefficient\n",
    "    \"Q7\": new_parity,           # parity\n",
    "    \"Q8\": [GFPR, GFNR],  # GFPR, GFNR\n",
    "    \"Q9\": [FP_0, FP_1, FN_0, FN_1]  # FP_0, FP_1, FN_0, FN_1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert np to json\n",
    "answers_json = {k: v.item() if isinstance(v, np.number) else \n",
    "                   [x.item() if isinstance(x, np.number) else x for x in v] \n",
    "                   if isinstance(v, list) else v \n",
    "                for k, v in answers.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a502e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('answers_hw2.txt', 'w') as file:\n",
    "    json.dump(answers_json, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d2fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
