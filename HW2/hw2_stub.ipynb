{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c621447",
   "metadata": {},
   "source": [
    "## Homework 2: Intro to bias and fairness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3b9642c",
   "metadata": {},
   "source": [
    "Download the German Credit dataset: https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
    "(use the “numeric” version of the data)\n",
    "\n",
    "Implement a (logistic regression) classification pipeline using an 80/20 test split. Use a regularization value of C = 1.\n",
    "\n",
    "Treat the 20th feature (i.e., feat[19] in the numeric data, which is\n",
    "related to housing) as the “sensitive attribute” i.e., z=1 if the feature value is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f42dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "german_credit = np.loadtxt('german.data-numeric')\n",
    "attrs = german_credit[:, :-1] \n",
    "labels = 2 - german_credit[:, -1] # (1 = Good,  2 = Bad) -> (0=Bad, 1=good)\n",
    "\n",
    "split_point = 800\n",
    "X_train, X_test = attrs[:split_point], attrs[split_point:]\n",
    "y_train, y_test = labels[:split_point], labels[split_point:]\n",
    "\n",
    "sensitive_attribute = 19\n",
    "\n",
    "model = LogisticRegression(C=1, max_iter=1000, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce91dbf0",
   "metadata": {},
   "source": [
    "1. Report the prevalence in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4845af",
   "metadata": {},
   "source": [
    "2. Report the per-group prevalence for z=0 and z=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence_0 = \n",
    "prevalence_1 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca0bdadb",
   "metadata": {},
   "source": [
    "3. What is the demographic parity (expressed as a ratio between z=0 and z=1) for your classifier on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parity = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d94e8371",
   "metadata": {},
   "source": [
    "4. Report TPR_0, TPR_1, FPR_0, and FPR_1 (see \"equal opportunity\" slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_0 = \n",
    "TPR_1 = \n",
    "\n",
    "FPR_0 = \n",
    "FPR_1 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cfa79c3",
   "metadata": {},
   "source": [
    "5. Compute PPV_0, PPV_1, NPV_0, and NPV_1 (see \"are fairness goals compatible\" slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662715ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPV_0 = \n",
    "PPV_1 = \n",
    "\n",
    "NPV_0 = \n",
    "NPV_1 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a3d072",
   "metadata": {},
   "source": [
    "6. Implement a \"fairness through unawareness\" classifier, i.e., don't use Z in your feature vector. Find the classifier coefficient which undergoes the largest (absolute value) change compared to the classifier with the feature included, and report its new coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b504483",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "\n",
    "new_coeff = \n",
    "biggest_change_idx = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a843563",
   "metadata": {},
   "source": [
    "7. Report the demographic parity of the classifier after implementing the above intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parity = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcdb181b",
   "metadata": {},
   "source": [
    "8. Report the Generalized False Positive Rate and Generalized False Negative Rate of your original (i.e., not the one with z excluded).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "GFPR = \n",
    "GFNR = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "968ab77b",
   "metadata": {},
   "source": [
    "9. (harder, 2 marks) Changing the classifier threshold (much as you would to generate an ROC curve) will change the False Positive and False Negative rates for both groups (i.e., FP_0, FP_1, FN_0, FN_1). Implement a \"fairness through unawareness\" classifier like you did in Question 6 but instead use feature 19 (i.e., feat[18]) as the sensitive attribute. Using this classifier, find the (non-trivial) threshold that comes closest to achieving Treatment Equality, and report the corresponding values of FP_0, FP_1, FN_0, and FN_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_attribute = 18\n",
    "new_model = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "\n",
    "FP_0, FP_1, FN_0, FN_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {\n",
    "    \"Q1\": prevalence,           # prevalence\n",
    "    \"Q2\": [prevalence_0, prevalence_1],  # prevalence_0, prevalence_1\n",
    "    \"Q3\": parity,           # parity\n",
    "    \"Q4\": [TPR_0, TPR_1, FPR_0, FPR_0], # TPR_0, TPR_1, FPR_0, FPR_1\n",
    "    \"Q5\": [PPV_0, PPV_1, NPV_0, NPV_1], # PPV_0, PPV_1, NPV_0, NPV_1\n",
    "    \"Q6\": [biggest_change_idx, new_coeff], # feature index, coefficient\n",
    "    \"Q7\": new_parity,           # parity\n",
    "    \"Q8\": [GFPR, GFNR],  # GFPR, GFNR\n",
    "    \"Q9\": [FP_0, FP_1, FN_0, FN_1]  # FP_0, FP_1, FN_0, FN_1\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee33efb0d710eab7aeb8151f4f8b45435eb2f95622dfa0123c8122f2ab63b67a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
