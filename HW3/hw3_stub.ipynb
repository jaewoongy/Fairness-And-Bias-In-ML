{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42df8800-44dc-4bb4-ac8c-a67a738b1b73",
   "metadata": {},
   "source": [
    "## HW 3: Fairness and Bias Interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e0ff3-f69a-4c78-887e-853b79d8ebfd",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "1. Go to the [Adult Dataset webpage](https://archive.ics.uci.edu/dataset/2/adult).\n",
    "2. Download and unzip the file in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308097ce-6488-4edf-9412-5cfd370a2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17d6755-e6e0-4ffc-b8c7-6c7569c61eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA LOADING ##\n",
    "header = [\"age\",\n",
    "          \"workclass\",\n",
    "          \"fnlwgt\",\n",
    "          \"education\",\n",
    "          \"education-num\",\n",
    "          \"marital-status\",\n",
    "          \"occupation\",\n",
    "          \"relationship\",\n",
    "          \"race\",\n",
    "          \"sex\",\n",
    "          \"capital-gain\",\n",
    "          \"capital-loss\",\n",
    "          \"hours-per-week\",\n",
    "          \"native-country\"]\n",
    "\n",
    "values = {\"workclass\": [\"Private\", \"Self-emp-not-inc\", \"Self-emp-inc\", \"Federal-gov\", \"Local-gov\", \"State-gov\", \"Without-pay\", \"Never-worked\"],\n",
    "          \"education\": [\"Bachelors\", \"Some-college\", \"11th\", \"HS-grad\", \"Prof-school\", \"Assoc-acdm\", \"Assoc-voc\", \"9th\", \"7th-8th\", \"12th\", \"Masters\", \"1st-4th\", \"10th\", \"Doctorate\", \"5th-6th\", \"Preschool\"],\n",
    "          \"marital-status\": [\"Married-civ-spouse\", \"Divorced\", \"Never-married\", \"Separated\", \"Widowed\", \"Married-spouse-absent\", \"Married-AF-spouse\"],\n",
    "          \"occupation\": [\"Tech-support\", \"Craft-repair\", \"Other-service\", \"Sales\", \"Exec-managerial\", \"Prof-specialty\", \"Handlers-cleaners\", \"Machine-op-inspct\", \"Adm-clerical\", \"Farming-fishing\", \"Transport-moving\", \"Priv-house-serv\", \"Protective-serv\", \"Armed-Forces\"],\n",
    "          \"relationship\": [\"Wife\", \"Own-child\", \"Husband\", \"Not-in-family\", \"Other-relative\", \"Unmarried\"],\n",
    "          \"race\": [\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"],\n",
    "          \"sex\": [\"Female\", \"Male\"],\n",
    "          \"native-country\": [\"United-States\", \"Cambodia\", \"England\", \"Puerto-Rico\", \"Canada\", \"Germany\", \"Outlying-US(Guam-USVI-etc)\", \"India\", \"Japan\", \"Greece\", \"South\", \"China\", \"Cuba\", \"Iran\", \"Honduras\", \"Philippines\", \"Italy\", \"Poland\", \"Jamaica\", \"Vietnam\", \"Mexico\", \"Portugal\", \"Ireland\", \"France\", \"Dominican-Republic\", \"Laos\", \"Ecuador\", \"Taiwan\", \"Haiti\", \"Columbia\", \"Hungary\", \"Guatemala\", \"Nicaragua\", \"Scotland\", \"Thailand\", \"Yugoslavia\", \"El-Salvador\", \"Trinadad&Tobago\", \"Peru\", \"Hong\", \"Holand-Netherlands\"]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daac1538-2dab-43a6-abe4-d2009e61cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(d):\n",
    "    f = [1]\n",
    "    for h in header:\n",
    "        if h in values:\n",
    "            onehot = [0]*len(values[h])\n",
    "            try:\n",
    "                onehot[values[h].index(d[h])] = 1 # not efficient! Should make an index\n",
    "            except Exception as e:\n",
    "                # Missing value\n",
    "                pass\n",
    "            f += onehot\n",
    "        else: # continuous\n",
    "            try:\n",
    "                f.append(float(d[h]))\n",
    "            except Exception as e:\n",
    "                # Missing value\n",
    "                f.append(0) # Replacing with zero probably not perfect!\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3015d2-d13a-41e6-bbb8-7102db1dbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "labels = []\n",
    "a = open(\"adult.data\", 'r')\n",
    "for l in a:\n",
    "    if len(l) <= 1: break # Last line of the dataset is empty\n",
    "    l = l.split(\", \") # Could use a csv library but probably no need to here\n",
    "    dataset.append(dict(zip(header, l)))\n",
    "    labels.append(l[-1].strip()) # Last entry in each row is the label\n",
    "\n",
    "X = [feat(d) for d in dataset]\n",
    "y = [inc == '>50K' for inc in labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test, d_train, d_test = train_test_split(X, y, dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7810e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 33.0, 0, 0, 0, 0, 1, 0, 0, 0, 198183.0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13.0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0.0, 0.0, 50.0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True\n",
      "{'age': '33', 'workclass': 'Local-gov', 'fnlwgt': '198183', 'education': 'Bachelors', 'education-num': '13', 'marital-status': 'Never-married', 'occupation': 'Prof-specialty', 'relationship': 'Not-in-family', 'race': 'White', 'sex': 'Female', 'capital-gain': '0', 'capital-loss': '0', 'hours-per-week': '50', 'native-country': 'United-States'}\n"
     ]
    }
   ],
   "source": [
    "len(X), len(X_train), len(X_test), len(d_train), len(d_test)\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(d_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9f0ebd-e71b-4944-bdb9-a67cdc4768fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa56d1b-fa6f-4b2e-8b92-1b68ca1a0ad4",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "\n",
    "#### (1 point)\n",
    "\n",
    "Implement a logistic regression classification pipeline using an `80/20` test split. Use a regularization value of $C = 1$.\n",
    "\n",
    "Treat “sex” as the “sensitive attribute” i.e., $z=1$ for females and $z=0$ for others.\n",
    "\n",
    "**Report:** The discrimination in the dataset (see \"pre-processing\" module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656250c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(X_tr, y_tr):\n",
    "    reg = LogisticRegression(C = 1, max_iter = 1000)\n",
    "    return reg.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1287e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd9125f-0557-433f-8dff-e366c5bc8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset discrimination: 0.196497\n"
     ]
    }
   ],
   "source": [
    "def discrimination_score(datapoints, labels):\n",
    "    labels = np.array(labels)\n",
    "    z_1_indices = [index for index, dict in enumerate(datapoints) if dict['sex'] == 'Male']\n",
    "    z_0_indices = [index for index, dict in enumerate(datapoints) if dict['sex'] == 'Female']\n",
    "    p_y_1_z_1 = np.mean(labels[z_1_indices])\n",
    "    p_y_1_z_0 = np.mean(labels[z_0_indices])\n",
    "    return p_y_1_z_1 - p_y_1_z_0\n",
    "\n",
    "dataset_discrimination = discrimination_score(d_train, y_train)\n",
    "print(f'Dataset discrimination: {dataset_discrimination:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12691525-fc51-4996-a3a9-de73325e2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = dataset_discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4bf92-e751-4738-8582-0f40b1cf4a89",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "\n",
    "#### (1 point)\n",
    "\n",
    "**Report:** The discrimination of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96bc6daa-dabc-4e19-b181-f734a1fc5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier discrimination (Q2): 0.180161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "mod = pipeline(X_train, y_train)\n",
    "preds_train_q2 = mod.predict(X_train)\n",
    "classifier_discrimination_q2 = discrimination_score(d_train, preds_train_q2)\n",
    "\n",
    "print(f'Classifier discrimination (Q2): {classifier_discrimination_q2:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5132a13-e8e1-46ac-b85a-723e6861afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = classifier_discrimination_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8acebff-a2f5-46c2-ad7e-eab124683e78",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "#### (1 point)\n",
    "\n",
    "Implement a \"massaging\" approach that improves the discrimination score by at least 3\\%.\n",
    "\n",
    "\n",
    "**Report:** The new discrimination score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af4615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = mod.predict_proba(X_train)[:, -1]\n",
    "z_1_indices = [index for index, dict in enumerate(d_train) if dict['sex'] == 'Male']\n",
    "z_0_indices = [index for index, dict in enumerate(d_train) if dict['sex'] == 'Female']\n",
    "female_neg = [i for i in z_0_indices if y_train[i] == 0]\n",
    "male_pos = [i for i in z_1_indices if y_train[i] == 1]\n",
    "probs = mod.predict_proba(X_train)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be11db-3a82-4778-8bb8-a5df7a280226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier discrimination (Q3):\t 0.166150\n",
      "Classifier relative improvement (Q3):\t 8.432616%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# find promotion candidates\n",
    "\n",
    "\n",
    "promote_candidates = sorted(female_neg, key=lambda x: probs[x], reverse=True)\n",
    "demote_candidates = sorted(male_pos, key=lambda x: probs[x])\n",
    "y_train_fixed_q3 = y_train\n",
    "for i in promote_candidates[:100]:\n",
    "    y_train_fixed_q3[i] = 1\n",
    "for i in demote_candidates[:100]:\n",
    "    y_train_fixed_q3[i] = 0\n",
    "\n",
    "# train model\n",
    "model_q3 = pipeline(X_train, y_train_fixed_q3)\n",
    "preds_train_q3 = model_q3.predict(X_train)\n",
    "classifier_discrimination_q3 = discrimination_score(d_train, preds_train_q3)\n",
    "\n",
    "print(f'Classifier discrimination (Q3):\\t {classifier_discrimination_q3:.6f}')\n",
    "print(f'Classifier relative improvement (Q3):\\t {100*(classifier_discrimination_q2 - classifier_discrimination_q3) / classifier_discrimination_q3:.6f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "377e7537-19e3-4ecd-a087-68c287a6e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = classifier_discrimination_q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfdcad-67a2-4a36-9915-f7e480802c25",
   "metadata": {},
   "source": [
    "## 3.4\n",
    "\n",
    "#### (2 points)\n",
    "\n",
    "Implement a \"reweighting\" approach that improves the discrimination score by at least 3%; report the new discrimination score.\n",
    "\n",
    "**Report:** The new discrimination score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "264926fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26048"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.zeros(len(d_train))\n",
    "len(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b755c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26048"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observed counts\n",
    "p_z_1_y_1 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if dictionary['sex'] == 'Female' and y_train[index] == 1]) / len(d_train)\n",
    "p_z_1_y_0 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if dictionary['sex'] == 'Female' and y_train[index] == 0]) / len(d_train)\n",
    "p_z_0_y_1 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if dictionary['sex'] == 'Male' and y_train[index] == 1]) / len(d_train)\n",
    "p_z_0_y_0 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if dictionary['sex'] == 'Male' and y_train[index] == 0]) / len(d_train)\n",
    "p_z_0 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if y_train[index] == 0]) / len(d_train)\n",
    "p_z_1 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if y_train[index] == 1]) / len(d_train)\n",
    "p_y_0 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if y_train[index] == 0]) / len(d_train)\n",
    "p_y_1 = len([(index, dictionary) for index, dictionary in enumerate(d_train) if y_train[index] == 1]) / len(d_train)\n",
    "\n",
    "weights = np.zeros(len(d_train))\n",
    "y_train_q4 = y_train\n",
    "\n",
    "for i, d in enumerate(d_train):\n",
    "    if y_train[i] == 1 and d['sex'] == 'Female':\n",
    "        weights[i] = p_y_1 * p_z_1 / p_z_1_y_1\n",
    "    elif y_train[i] == 0 and d['sex'] == 'Female':\n",
    "        weights[i] = p_y_0 * p_z_1 / p_z_1_y_0\n",
    "    elif y_train[i] == 1 and d['sex'] == 'Male':\n",
    "        weights[i] = p_y_1 * p_z_0 / p_z_0_y_1\n",
    "    else:\n",
    "        weights[i] = p_y_0 * p_z_0 / p_z_0_y_0\n",
    "\n",
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c2db3fe-ec1e-4612-a58d-f2cb74e8d630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier discrimination (Q4):\t 0.031866\n",
      "Classifier relative improvement (Q4):\t 82.312297%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_q4 = LogisticRegression(C=1, max_iter=1000)\n",
    "model_q4.fit(X_train, y_train, sample_weight=weights)\n",
    "preds_train_q4 = model_q4.predict(X_train)\n",
    "classifier_discrimination_q4 = discrimination_score(d_train, preds_train_q4)\n",
    "\n",
    "print(f'Classifier discrimination (Q4):\\t {classifier_discrimination_q4:.6f}')\n",
    "print(f'Classifier relative improvement (Q4):\\t {100*(classifier_discrimination_q2 - classifier_discrimination_q4) / classifier_discrimination_q2:.6f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07d70156-c74b-4569-9240-0f13768dc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = classifier_discrimination_q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bbb0a0-b167-4d8d-86dd-3614b0461a8d",
   "metadata": {},
   "source": [
    "## 3.5\n",
    "\n",
    "#### (2 points)\n",
    "\n",
    "Implement a \"post processing\" (affirmative action) policy. Lowering per-group thresholds will increase both the (per-group) FPR and the (per-group) TPR. For whichever group has the lower TPR, lower the threshold until the TPR for both groups is (as close as possible to) equal. Report the rates (TPR_0, TPR_1, FPR_0, and FPR_1) for both groups.\n",
    "\n",
    "**Report:** The TPR and FPR rates for both groups as a list: `[TPR_0, TPR_1, FPR_0, FPR_1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5ff48ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def get_rates(y_true, y_pred, group_indices):\n",
    "    predicted_true = sum(1 for i in group_indices if y_true[i] == 1 and y_pred[i] == 1)\n",
    "    predicted_false = sum(1 for i in group_indices if y_true[i] == 0 and y_pred[i] == 1)\n",
    "    true_positive = sum(1 for i in group_indices if y_true[i] == 1)\n",
    "    true_negative = sum(1 for i in group_indices if y_true[i] == 0)\n",
    "    tpr = predicted_true / true_positive if true_positive > 0 else 0\n",
    "    fpr = predicted_false / true_negative if true_negative > 0 else 0\n",
    "    return tpr, fpr\n",
    "\n",
    "mod = LogisticRegression(C=1, max_iter=1000)\n",
    "mod.fit(X_train, y_train)\n",
    "y_pred = mod.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7fb547ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 6513, 6513)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_indices_test = [i for i, d in enumerate(d_test) if d['sex'] == 'Female']\n",
    "male_indices_test = [i for i, d in enumerate(d_test) if d['sex'] == 'Male']\n",
    "len(female_indices_test), len(d_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7681ae97",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tpr, fpr \u001b[38;5;241m=\u001b[39m get_rates(y_test, y_pred, female_indices)\n\u001b[1;32m      2\u001b[0m tpr, fpr\n",
      "Cell \u001b[0;32mIn[96], line 2\u001b[0m, in \u001b[0;36mget_rates\u001b[0;34m(y_true, y_pred, group_indices)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rates\u001b[39m(y_true, y_pred, group_indices):\n\u001b[0;32m----> 2\u001b[0m     predicted_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m group_indices \u001b[38;5;28;01mif\u001b[39;00m y_true[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m     predicted_false \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m group_indices \u001b[38;5;28;01mif\u001b[39;00m y_true[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     true_positive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m group_indices \u001b[38;5;28;01mif\u001b[39;00m y_true[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[96], line 2\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rates\u001b[39m(y_true, y_pred, group_indices):\n\u001b[0;32m----> 2\u001b[0m     predicted_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m group_indices \u001b[38;5;28;01mif\u001b[39;00m y_true[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m     predicted_false \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m group_indices \u001b[38;5;28;01mif\u001b[39;00m y_true[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     true_positive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m group_indices \u001b[38;5;28;01mif\u001b[39;00m y_true[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tpr, fpr = get_rates(y_test, y_pred, female_indices)\n",
    "tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f672488e-3b41-432c-a325-179bc85534d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "male_thresh = 0.5\n",
    "female_thresh_q5 = ...\n",
    "ans_q5 = [None, None, None, None]  # [TPR_male, TPR_female, FPR_male, FPR_female]\n",
    "\n",
    "print(ans_q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2cceea87-8bf5-4428-b2ae-75e19bc18d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = ans_q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77a5c2-e5e8-4ae9-ac3f-c6fb40112d1c",
   "metadata": {},
   "source": [
    "## 3.6\n",
    "\n",
    "#### (1 point)\n",
    "\n",
    "Modify the solution from Q5 to exclude the sensitive attribute ($z$) from the classifier’s feature vector. Implement the same strategy as in Q5.\n",
    "\n",
    "**Report:** The TPR and FPR rates for both groups as a list: `[TPR_0, TPR_1, FPR_0, FPR_1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c384e3da-e799-4e51-a73c-6b9a67292886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "male_thresh = 0.5\n",
    "female_thresh_q6 = ...\n",
    "ans_q6 = [None, None, None, None]  # [TPR_male, TPR_female, FPR_male, FPR_female]\n",
    "\n",
    "print(ans_q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab419f7c-bbd5-4c7a-9d22-ecb7622354ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = ans_q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b6ddb-4f70-4b84-b107-ac725e561097",
   "metadata": {},
   "source": [
    "## 3.7\n",
    "\n",
    "#### (1 point)\n",
    "\n",
    "Again modifying the solution from Q5, train two separate classifiers, one for $z=0$ and one for $z=1$. Implement the same strategy as in Q5.\n",
    "\n",
    "**Report:** The TPR and FPR rates for both groups as a list: `[TPR_0, TPR_1, FPR_0, FPR_1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f1e5b8b2-1726-4525-b4f0-001f6a09e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [YOUR CODE HERE]\n",
    "\n",
    "model_male_q7 = ...\n",
    "model_female_q7 = ...\n",
    "\n",
    "scores_q7 = ...\n",
    "\n",
    "\n",
    "male_thresh = 0.5\n",
    "female_thresh_q7 = ...\n",
    "ans_q7 = [None, None, None, None]  # [TPR_male, TPR_female, FPR_male, FPR_female]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc05fed8-4ba2-4f2b-95d3-c1cf5a76fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = ans_q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65b8d4-5a3c-44cf-bafc-e5295b4b504f",
   "metadata": {},
   "source": [
    "## Saving Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5174381f-5cd8-4087-9f70-fed6dddc9ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "50192dcf-8859-4df8-a7bb-276440f5bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra step to make things serializable\n",
    "\n",
    "with open('answers.txt', 'w' ) as f:\n",
    "    json.dump(answers, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0be4d3-63bb-483a-b65e-d217afb8f356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bff8bb-947c-4df9-b71c-655c413fd6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
